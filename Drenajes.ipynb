{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Corregir Elevaciones Drenajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV guardado en C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\vertices_xyz.csv\n",
      "   ID_Drenaje          X          Y          Z    abscisa  E1_Corregida\n",
      "0           1  4794637.0  2276937.0  811.59204   0.000000     811.59204\n",
      "1           1  4794633.0  2276941.0  811.03140   5.656854     811.03140\n",
      "2           1  4794631.0  2276943.0  810.37940   8.485281     810.37940\n",
      "3           1  4794629.1  2276945.0  809.55304  11.243220     809.55304\n",
      "4           1  4794627.4  2276947.0  808.62480  13.862179     808.62480\n",
      "Archivo LAS creado exitosamente.\n",
      "Shapefile de líneas 3D creado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Point, MultiLineString, LineString\n",
    "import math\n",
    "import numpy as np\n",
    "import laspy\n",
    "\n",
    "# --- Cargar archivos ---\n",
    "shapefile_path = r\"C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\Drenaje.shp\"  # Ruta del shapefile de drenajes\n",
    "dtm_path = r\"C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\\\Modelo.tif\"  # Ruta del DTM\n",
    "output_csv = r\"C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\vertices_xyz.csv\"  # Nombre del archivo CSV de salida\n",
    "output_csv_2 = r\"C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\vertices_OK_xyz.csv\"\n",
    "lasfile=r\"C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\drenajes.las\"\n",
    "lineshp=r\"C:\\Users\\nicol\\Downloads\\Prueba_Drenajes\\Prueba_Drenajes\\drenajes2.shp\"\n",
    "# Cargar drenajes\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Agregar un ID único para cada drenaje\n",
    "gdf[\"ID_Drenaje\"] = range(1, len(gdf) + 1)\n",
    "\n",
    "# Extraer todos los vértices de las líneas\n",
    "vertices = []\n",
    "with rasterio.open(dtm_path) as dtm:\n",
    "    transform = dtm.transform\n",
    "    for idx, row in gdf.iterrows():\n",
    "        geom = row.geometry\n",
    "        if isinstance(geom, MultiLineString):\n",
    "            lines = geom.geoms\n",
    "        else:\n",
    "            lines = [geom]\n",
    "        \n",
    "        for line in lines:\n",
    "            coords = np.array(line.coords)\n",
    "            x, y = coords[:, 0], coords[:, 1]\n",
    "            \n",
    "            # Usar interpolación bilineal con sample()\n",
    "            sample_points = [(xi, yi) for xi, yi in zip(x, y)]\n",
    "            z_values = [val[0] for val in dtm.sample(sample_points, indexes=1)]\n",
    "            \n",
    "            for xi, yi, zi in zip(x, y, z_values):\n",
    "                vertices.append([row[\"ID_Drenaje\"], xi, yi, zi])\n",
    "\n",
    "# Crear un DataFrame con los puntos\n",
    "vertices_df = pd.DataFrame(vertices, columns=[\"ID_Drenaje\", \"X\", \"Y\", \"Z\"])\n",
    "vertices_df[\"abscisa\"]=0\n",
    "# Abscisa\n",
    "initial_point = (vertices_df.iloc[0]['X'], vertices_df.iloc[0]['Y'])\n",
    "\n",
    "# Lista para almacenar las distancias calculadas\n",
    "distances = []\n",
    "\n",
    "# Calcular la distancia entre el primer punto y los demás\n",
    "for index, row in vertices_df.iterrows():\n",
    "    current_point = (row['X'], row['Y'])\n",
    "    # Aplicar la fórmula de distancia euclidiana\n",
    "    distance = math.sqrt((current_point[0] - initial_point[0]) ** 2 + (current_point[1] - initial_point[1]) ** 2)\n",
    "    # Almacenar la distancia\n",
    "    distances.append(distance)\n",
    "# Añadir la columna de distancias al DataFrame\n",
    "vertices_df['abscisa'] = distances\n",
    "# Guardar a CSV\n",
    "vertices_df.to_csv(output_csv, index=False)\n",
    "print(f\"Archivo CSV guardado en {output_csv}\")\n",
    "\n",
    "#Corregir Elevaciones\n",
    "def corregir_elevaciones(df): \n",
    "    df = df.copy().reset_index(drop=True)  # Reiniciar índice dentro del grupo\n",
    "    elevaciones_corregidas = df[\"Z\"].values.copy()\n",
    "\n",
    "    ultimo_correcto_idx = 0\n",
    "    i = 1\n",
    "\n",
    "    while i < len(df):\n",
    "        if elevaciones_corregidas[i] > elevaciones_corregidas[ultimo_correcto_idx]:\n",
    "            inicio_idx = ultimo_correcto_idx\n",
    "\n",
    "            while i < len(df) and elevaciones_corregidas[i] > elevaciones_corregidas[inicio_idx]:\n",
    "                i += 1  \n",
    "\n",
    "            if i < len(df):  \n",
    "                x1, y1 = df.loc[inicio_idx, \"abscisa\"], elevaciones_corregidas[inicio_idx]\n",
    "                x2, y2 = df.loc[i, \"abscisa\"], elevaciones_corregidas[i]\n",
    "\n",
    "                for j in range(inicio_idx + 1, i):\n",
    "                    x = df.loc[j, \"abscisa\"]\n",
    "                    elevaciones_corregidas[j] = y1 + (y2 - y1) * (x - x1) / (x2 - x1)\n",
    "\n",
    "        ultimo_correcto_idx = i  \n",
    "        i += 1\n",
    "\n",
    "    df[\"E1_Corregida\"] = elevaciones_corregidas\n",
    "    return df\n",
    "\n",
    "\n",
    "# Cargar el CSV\n",
    "df = pd.read_csv(output_csv)\n",
    "# Aplicar la corrección por cada grupo de ID\n",
    "df_corregido = df.groupby(\"ID_Drenaje\", group_keys=False).apply(corregir_elevaciones)\n",
    "\n",
    "# Guardar el resultado corregido\n",
    "df_corregido.to_csv(output_csv_2, index=False)\n",
    "\n",
    "# Mostrar una vista previa del resultado\n",
    "print(df_corregido.head())\n",
    "\n",
    "#Exportar a LAS\n",
    "\n",
    "# Crear archivo LAS\n",
    "header = laspy.LasHeader(point_format=3, version=\"1.2\")  # Formato LAS 1.2\n",
    "las = laspy.LasData(header)\n",
    "\n",
    "# Asignar coordenadas desde el DataFrame\n",
    "las.x = np.array(df_corregido[\"X\"])\n",
    "las.y = np.array(df_corregido[\"Y\"])\n",
    "las.z = np.array(df_corregido[\"E1_Corregida\"])\n",
    "\n",
    "# Guardar archivo LAS\n",
    "las.write(lasfile)\n",
    "\n",
    "print(\"Archivo LAS creado exitosamente.\")\n",
    "\n",
    "\n",
    "# Función para convertir puntos en líneas 3D\n",
    "def puntos_a_linea(grupo):\n",
    "    # Ordenar los puntos en el drenaje según el orden consecutivo\n",
    "    grupo = grupo.sort_index()\n",
    "    \n",
    "    # Crear la geometría LineString con coordenadas (X, Y, Z)\n",
    "    puntos = grupo.apply(lambda row: (row[\"X\"], row[\"Y\"], row[\"E1_Corregida\"]), axis=1).tolist()\n",
    "    return LineString(puntos)\n",
    "\n",
    "# Crear líneas por cada ID\n",
    "gdf = df_corregido.groupby(\"ID_Drenaje\").apply(puntos_a_linea).reset_index(name=\"geometry\")\n",
    "\n",
    "# WKT \n",
    "crs_9377 = (\n",
    "    \"PROJCRS[\\\"MAGNA-SIRGAS 2018 / Origen-Nacional\\\",\"\n",
    "    \"    BASEGEOGCRS[\\\"MAGNA-SIRGAS 2018\\\",\"\n",
    "    \"        DATUM[\\\"Marco Geocentrico Nacional de Referencia 2018\\\",\"\n",
    "    \"            ELLIPSOID[\\\"GRS 1980\\\",6378137,298.257222101,\"\n",
    "    \"                LENGTHUNIT[\\\"metre\\\",1]]],\"\n",
    "    \"        PRIMEM[\\\"Greenwich\\\",0,\"\n",
    "    \"            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\"\n",
    "    \"        ID[\\\"EPSG\\\",20046]],\"\n",
    "    \"    CONVERSION[\\\"Colombia Transverse Mercator\\\",\"\n",
    "    \"        METHOD[\\\"Transverse Mercator\\\",\"\n",
    "    \"            ID[\\\"EPSG\\\",9807]],\"\n",
    "    \"        PARAMETER[\\\"Latitude of natural origin\\\",4,\"\n",
    "    \"            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\"\n",
    "    \"            ID[\\\"EPSG\\\",8801]],\"\n",
    "    \"        PARAMETER[\\\"Longitude of natural origin\\\",-73,\"\n",
    "    \"            ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\"\n",
    "    \"            ID[\\\"EPSG\\\",8802]],\"\n",
    "    \"        PARAMETER[\\\"Scale factor at natural origin\\\",0.9992,\"\n",
    "    \"            SCALEUNIT[\\\"unity\\\",1],\"\n",
    "    \"            ID[\\\"EPSG\\\",8805]],\"\n",
    "    \"        PARAMETER[\\\"False easting\\\",5000000,\"\n",
    "    \"            LENGTHUNIT[\\\"metre\\\",1],\"\n",
    "    \"            ID[\\\"EPSG\\\",8806]],\"\n",
    "    \"        PARAMETER[\\\"False northing\\\",2000000,\"\n",
    "    \"            LENGTHUNIT[\\\"metre\\\",1],\"\n",
    "    \"            ID[\\\"EPSG\\\",8807]]],\"\n",
    "    \"    CS[Cartesian,2],\"\n",
    "    \"        AXIS[\\\"northing (N)\\\",north,\"\n",
    "    \"            ORDER[1],\"\n",
    "    \"            LENGTHUNIT[\\\"metre\\\",1]],\"\n",
    "    \"        AXIS[\\\"easting (E)\\\",east,\"\n",
    "    \"            ORDER[2],\"\n",
    "    \"            LENGTHUNIT[\\\"metre\\\",1]],\"\n",
    "    \"    USAGE[\"\n",
    "    \"        SCOPE[\\\"Cadastre, topographic mapping.\\\"],\"\n",
    "    \"        AREA[\\\"Colombia - onshore and offshore. Includes San Andres y Providencia, Malpelo Islands, Roncador Bank, Serrana Bank and Serranilla Bank.\\\"],\"\n",
    "    \"        BBOX[-4.23,-84.77,15.51,-66.87]],\"\n",
    "    \"    ID[\\\"EPSG\\\",9377]]\"\n",
    ")\n",
    "\n",
    "# Convertir a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry=\"geometry\", crs=crs_9377)  # Usa tu EPSG\n",
    "\n",
    "# Guardar como shapefile de líneas 3D\n",
    "gdf.to_file(lineshp, driver=\"ESRI Shapefile\")\n",
    "\n",
    "print(\"Shapefile de líneas 3D creado exitosamente.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 -- Funcion Corregir elevaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_elevaciones(df): #Funcion para encontrar errores y corregirlos.\n",
    "    df = df.copy()\n",
    "    elevaciones_corregidas = df[\"Z\"].values.copy()\n",
    " \n",
    "    ultimo_correcto_idx = 0  # Índice del último punto correcto\n",
    "    i = 1\n",
    "    \n",
    "    while i < len(df):\n",
    "        if elevaciones_corregidas[i] > elevaciones_corregidas[ultimo_correcto_idx]:  # Error detectado\n",
    "            inicio_idx = ultimo_correcto_idx\n",
    "            \n",
    "            while i < len(df) and elevaciones_corregidas[i] > elevaciones_corregidas[inicio_idx]:\n",
    "                i += 1  # Buscar el primer punto donde la elevación vuelve a ser decreciente\n",
    "\n",
    "            if i < len(df):  # Se encontró un punto válido\n",
    "                x1, y1 = df.loc[inicio_idx, \"abscisa\"], elevaciones_corregidas[inicio_idx]\n",
    "                x2, y2 = df.loc[i, \"abscisa\"], elevaciones_corregidas[i]\n",
    "\n",
    "                for j in range(inicio_idx + 1, i):\n",
    "                    x = df.loc[j, \"abscisa\"]\n",
    "                    elevaciones_corregidas[j] = y1 + (y2 - y1) * (x - x1) / (x2 - x1)\n",
    "\n",
    "        ultimo_correcto_idx = i  # Actualizar el último punto correcto\n",
    "        i += 1\n",
    "   \n",
    "    df[\"E1_Corregida\"] = elevaciones_corregidas\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno37_20240321",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
